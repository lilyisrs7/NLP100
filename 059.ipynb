{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-18 21:30:06,117] A new study created in memory with name: no-name-3fa6d95f-48bd-4709-9c08-781e4a6de43a\n",
      "[I 2023-09-18 21:30:21,165] Trial 0 finished with value: 0.7316341829085458 and parameters: {'random_state': 6, 'l1_ratio': 0.7000000000000001}. Best is trial 0 with value: 0.7316341829085458.\n",
      "[I 2023-09-18 21:30:32,113] Trial 1 finished with value: 0.7301349325337332 and parameters: {'random_state': 6, 'l1_ratio': 0.5}. Best is trial 0 with value: 0.7316341829085458.\n",
      "[I 2023-09-18 21:30:48,485] Trial 2 finished with value: 0.7316341829085458 and parameters: {'random_state': 4, 'l1_ratio': 0.7000000000000001}. Best is trial 0 with value: 0.7316341829085458.\n",
      "[I 2023-09-18 21:31:20,914] Trial 3 finished with value: 0.7361319340329835 and parameters: {'random_state': 4, 'l1_ratio': 0.9}. Best is trial 3 with value: 0.7361319340329835.\n",
      "[I 2023-09-18 21:31:30,955] Trial 4 finished with value: 0.7293853073463268 and parameters: {'random_state': 10, 'l1_ratio': 0.4}. Best is trial 3 with value: 0.7361319340329835.\n",
      "[I 2023-09-18 21:31:41,854] Trial 5 finished with value: 0.7301349325337332 and parameters: {'random_state': 8, 'l1_ratio': 0.5}. Best is trial 3 with value: 0.7361319340329835.\n",
      "/Users/kogayurie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-09-18 21:32:22,171] Trial 6 finished with value: 0.7368815592203898 and parameters: {'random_state': 6, 'l1_ratio': 1.0}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:32:26,966] Trial 7 finished with value: 0.7278860569715142 and parameters: {'random_state': 0, 'l1_ratio': 0.0}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:32:56,867] Trial 8 finished with value: 0.7361319340329835 and parameters: {'random_state': 0, 'l1_ratio': 0.9}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:33:26,446] Trial 9 finished with value: 0.7361319340329835 and parameters: {'random_state': 8, 'l1_ratio': 0.9}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:33:45,890] Trial 10 finished with value: 0.7308845577211395 and parameters: {'random_state': 10, 'l1_ratio': 0.8}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:34:05,401] Trial 11 finished with value: 0.7308845577211395 and parameters: {'random_state': 5, 'l1_ratio': 0.8}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:34:20,099] Trial 12 finished with value: 0.7316341829085458 and parameters: {'random_state': 1, 'l1_ratio': 0.7000000000000001}. Best is trial 6 with value: 0.7368815592203898.\n",
      "/Users/kogayurie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-09-18 21:35:03,573] Trial 13 finished with value: 0.7368815592203898 and parameters: {'random_state': 1, 'l1_ratio': 1.0}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:35:13,063] Trial 14 finished with value: 0.7293853073463268 and parameters: {'random_state': 5, 'l1_ratio': 0.4}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:35:32,793] Trial 15 finished with value: 0.7308845577211395 and parameters: {'random_state': 2, 'l1_ratio': 0.8}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:35:44,953] Trial 16 finished with value: 0.7308845577211395 and parameters: {'random_state': 5, 'l1_ratio': 0.6000000000000001}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:35:57,273] Trial 17 finished with value: 0.7308845577211395 and parameters: {'random_state': 0, 'l1_ratio': 0.6000000000000001}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:36:09,685] Trial 18 finished with value: 0.7308845577211395 and parameters: {'random_state': 6, 'l1_ratio': 0.6000000000000001}. Best is trial 6 with value: 0.7368815592203898.\n",
      "[I 2023-09-18 21:36:24,489] Trial 19 finished with value: 0.7316341829085458 and parameters: {'random_state': 10, 'l1_ratio': 0.7000000000000001}. Best is trial 6 with value: 0.7368815592203898.\n",
      "/Users/kogayurie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-09-18 21:37:04,050] A new study created in memory with name: no-name-54e87eb1-b933-4a00-88d6-e2a904e8c208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression\n",
      "train: 0.7391304347826086\n",
      "test: 0.7338830584707646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-18 21:37:08,136] Trial 0 finished with value: 0.7256371814092953 and parameters: {'n_estimators': 101, 'max_depth': 4, 'random_state': 6}. Best is trial 0 with value: 0.7256371814092953.\n",
      "[I 2023-09-18 21:37:11,388] Trial 1 finished with value: 0.7263868065967016 and parameters: {'n_estimators': 101, 'max_depth': 3, 'random_state': 7}. Best is trial 1 with value: 0.7263868065967016.\n",
      "[I 2023-09-18 21:37:16,246] Trial 2 finished with value: 0.7286356821589205 and parameters: {'n_estimators': 99, 'max_depth': 5, 'random_state': 10}. Best is trial 2 with value: 0.7286356821589205.\n",
      "[I 2023-09-18 21:37:20,321] Trial 3 finished with value: 0.7256371814092953 and parameters: {'n_estimators': 98, 'max_depth': 4, 'random_state': 5}. Best is trial 2 with value: 0.7286356821589205.\n",
      "[I 2023-09-18 21:37:25,249] Trial 4 finished with value: 0.7293853073463268 and parameters: {'n_estimators': 101, 'max_depth': 5, 'random_state': 0}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:26,601] Trial 5 finished with value: 0.7233883058470765 and parameters: {'n_estimators': 91, 'max_depth': 1, 'random_state': 9}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:31,924] Trial 6 finished with value: 0.7293853073463268 and parameters: {'n_estimators': 106, 'max_depth': 5, 'random_state': 10}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:36,207] Trial 7 finished with value: 0.7278860569715142 and parameters: {'n_estimators': 106, 'max_depth': 3, 'random_state': 8}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:40,159] Trial 8 finished with value: 0.7278860569715142 and parameters: {'n_estimators': 92, 'max_depth': 4, 'random_state': 1}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:43,756] Trial 9 finished with value: 0.7203898050974513 and parameters: {'n_estimators': 109, 'max_depth': 3, 'random_state': 4}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:47,666] Trial 10 finished with value: 0.724887556221889 and parameters: {'n_estimators': 95, 'max_depth': 4, 'random_state': 5}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:48,996] Trial 11 finished with value: 0.7241379310344828 and parameters: {'n_estimators': 101, 'max_depth': 1, 'random_state': 6}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:53,054] Trial 12 finished with value: 0.7256371814092953 and parameters: {'n_estimators': 102, 'max_depth': 4, 'random_state': 10}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:55,431] Trial 13 finished with value: 0.7233883058470765 and parameters: {'n_estimators': 104, 'max_depth': 2, 'random_state': 4}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:56,920] Trial 14 finished with value: 0.7181409295352323 and parameters: {'n_estimators': 104, 'max_depth': 1, 'random_state': 7}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:37:59,285] Trial 15 finished with value: 0.724887556221889 and parameters: {'n_estimators': 104, 'max_depth': 2, 'random_state': 1}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:38:01,460] Trial 16 finished with value: 0.724887556221889 and parameters: {'n_estimators': 96, 'max_depth': 2, 'random_state': 6}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:38:06,210] Trial 17 finished with value: 0.7278860569715142 and parameters: {'n_estimators': 99, 'max_depth': 5, 'random_state': 1}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:38:07,449] Trial 18 finished with value: 0.717391304347826 and parameters: {'n_estimators': 94, 'max_depth': 1, 'random_state': 7}. Best is trial 4 with value: 0.7293853073463268.\n",
      "[I 2023-09-18 21:38:10,450] Trial 19 finished with value: 0.7233883058470765 and parameters: {'n_estimators': 95, 'max_depth': 3, 'random_state': 2}. Best is trial 4 with value: 0.7293853073463268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest classifier\n",
      "train: 0.736319340329835\n",
      "test: 0.7233883058470765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.read_csv('train.feature.txt')\n",
    "X_train = df_train.drop(columns=['category', 'title'])\n",
    "y_train = df_train['category']\n",
    "df_valid = pd.read_csv('valid.feature.txt')\n",
    "X_valid = df_valid.drop(columns=['category', 'title'])\n",
    "y_valid = df_valid['category']\n",
    "df_test = pd.read_csv('test.feature.txt')\n",
    "X_test = df_test.drop(columns=['category', 'title'])\n",
    "y_test = df_test['category']\n",
    "\n",
    "def objective_lr(trial):\n",
    "    random_state = trial.suggest_int('random_state', 0, 10)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1, step=0.1)\n",
    "    model_lr = LogisticRegression(penalty='elasticnet', random_state=random_state, solver='saga', max_iter=1000,\n",
    "                                  l1_ratio=l1_ratio)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    return accuracy_score(y_valid, model_lr.predict(X_valid))\n",
    "\n",
    "def objective_rfc(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 90, 110)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 5)\n",
    "    random_state = trial.suggest_int('random_state', 0, 10)\n",
    "    model_rfc = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    model_rfc.fit(X_train, y_train)\n",
    "    return accuracy_score(y_valid, model_rfc.predict(X_valid))\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0), direction='maximize')\n",
    "study.optimize(objective_lr, n_trials=20)\n",
    "model_lr = LogisticRegression(penalty='elasticnet', random_state=study.best_params['random_state'], solver='saga',\n",
    "                              max_iter=1000, l1_ratio=study.best_params['l1_ratio'])\n",
    "model_lr.fit(X_train, y_train)\n",
    "print('logistic regression')\n",
    "print('train:', accuracy_score(y_train, model_lr.predict(X_train)))\n",
    "print('test:', accuracy_score(y_test, model_lr.predict(X_test)))\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0), direction='maximize')\n",
    "study.optimize(objective_rfc, n_trials=20)\n",
    "model_rfc = RandomForestClassifier(n_estimators=study.best_params['n_estimators'],\n",
    "                                   max_depth=study.best_params['max_depth'],\n",
    "                                   random_state=study.best_params['random_state'])\n",
    "model_rfc.fit(X_train, y_train)\n",
    "print('random forest classifier')\n",
    "print('train:', accuracy_score(y_train, model_rfc.predict(X_train)))\n",
    "print('test:', accuracy_score(y_test, model_rfc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression\n",
    "parameters: {'random_state': 6, 'l1_ratio': 1.0}  \n",
    "train: 0.7391304347826086  \n",
    "valid: 0.7368815592203898  \n",
    "test: 0.7338830584707646\n",
    "### random forest classifier\n",
    "parameters: {'n_estimators': 101, 'max_depth': 5, 'random_state': 0}  \n",
    "train: 0.736319340329835  \n",
    "valid: 0.7293853073463268  \n",
    "test: 0.7233883058470765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
